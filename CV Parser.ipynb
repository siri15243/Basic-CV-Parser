{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CV Parser","provenance":[],"authorship_tag":"ABX9TyPIRzwlEmM0n71KNP6nT/qn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"4Uwg-UJRHIrF","executionInfo":{"status":"error","timestamp":1640243262127,"user_tz":-330,"elapsed":512,"user":{"displayName":"Srikanth Vemula","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12636352860741150355"}},"outputId":"4da7687a-bf1e-44a8-bf06-fa94077c29e4"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-931185fa88ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_level\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mextract_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pdfminer'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from pdfminer.high_level import extract_text\n","\n","def extract_text_from_pdf(pdf_path):\n","    return extract_text(pdf_path)\n","\n","\n","# if __name__ == '__main__':\n","#     print(extract_text_from_pdf('Alice Clark CV.pdf'))"]},{"cell_type":"code","source":["import docx2txt\n","\n","\n","def extract_text_from_docx(docx_path):\n","    txt = docx2txt.process(docx_path)\n","    if txt:\n","        return txt.replace('\\t', ' ')\n","    return None\n","\n","\n","# if __name__ == '__main__':\n","#     print(extract_text_from_docx('Alice Clark CV.docx')) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"VJ9wvVbGHbIk","executionInfo":{"status":"error","timestamp":1640243367385,"user_tz":-330,"elapsed":357,"user":{"displayName":"Srikanth Vemula","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12636352860741150355"}},"outputId":"8d204732-faed-4f52-a1ea-b6d1448901d1"},"execution_count":7,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-b392aadd177b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdocx2txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_text_from_docx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocx_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocx2txt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocx_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'docx2txt'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["import docx2txt\n","import nltk\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","\n","\n","def extract_text_from_docx(docx_path):\n","    txt = docx2txt.process(docx_path)\n","    if txt:\n","        return txt.replace('\\t', ' ')\n","    return None\n","\n","\n","def extract_names(txt):\n","    person_names = []\n","\n","    for sent in nltk.sent_tokenize(txt):\n","        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n","            if hasattr(chunk, 'label') and chunk.label() == 'PERSON':\n","                person_names.append(\n","                    ' '.join(chunk_leave[0] for chunk_leave in chunk.leaves())\n","                )\n","\n","    return person_names[0]\n","\n","\n","# if __name__ == '__main__':\n","#     text = extract_text_from_docx('Alice Clark CV.docx')\n","#     names = extract_names(text)\n","\n","#     if names:\n","#         print(names[0]) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"nTeK7-FgHbfp","executionInfo":{"status":"error","timestamp":1640243370417,"user_tz":-330,"elapsed":402,"user":{"displayName":"Srikanth Vemula","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12636352860741150355"}},"outputId":"9f1d85db-78b1-450f-eb19-7c7199a7d3c9"},"execution_count":8,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-465d0d6a8bbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdocx2txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'averaged_perceptron_tagger'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'docx2txt'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["import re\n","import subprocess  \n","\n","PHONE_REG = re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n","\n","\n","def doc_to_text_catdoc(file_path):\n","    try:\n","        process = subprocess.Popen(  \n","            ['catdoc', '-w', file_path],\n","            stdout=subprocess.PIPE,\n","            stderr=subprocess.PIPE,\n","            universal_newlines=True,\n","        )\n","    except (\n","        FileNotFoundError,\n","        ValueError,\n","        subprocess.TimeoutExpired,\n","        subprocess.SubprocessError,\n","    ) as err:\n","        return (None, str(err))\n","    else:\n","        stdout, stderr = process.communicate()\n","\n","    return (stdout.strip(), stderr.strip())\n","\n","\n","def extract_phone_number(resume_text):\n","    phone = re.findall(PHONE_REG, resume_text)\n","\n","    if phone:\n","        number = ''.join(phone[0])\n","\n","        if resume_text.find(number) >= 0 and len(number) < 16:\n","            return number\n","    return None\n","\n","\n","# if __name__ == '__main__':\n","#     text = extract_text_from_docx('Smith Resume.docx')\n","#     phone_number = extract_phone_number(text)\n","\n","#     print(phone_number)"],"metadata":{"id":"d08PUQVdHeIu","executionInfo":{"status":"ok","timestamp":1640243263857,"user_tz":-330,"elapsed":16,"user":{"displayName":"Srikanth Vemula","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12636352860741150355"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","from pdfminer.high_level import extract_text\n","\n","EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n","\n","\n","def extract_text_from_pdf(pdf_path):\n","    return extract_text(pdf_path)\n","\n","\n","def extract_emails(resume_text):\n","    return re.findall(EMAIL_REG, resume_text)\n","\n","\n","# if __name__ == '__main__':\n","#     text = extract_text_from_docx('Smith Resume.docx')\n","#     emails = extract_emails(text)\n","\n","#     if emails:\n","#         print(emails[0]) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"idnh2mvEHfbS","executionInfo":{"status":"error","timestamp":1640243269002,"user_tz":-330,"elapsed":341,"user":{"displayName":"Srikanth Vemula","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12636352860741150355"}},"outputId":"a9fced66-7397-4706-b10a-06357ee5ae33"},"execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-b85106f60eba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_level\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mEMAIL_REG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pdfminer'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["import docx2txt\n","import nltk\n","\n","nltk.download('stopwords')\n","\n","# you may read the database from a csv file or some other database\n","SKILLS_DB = [\n","    'machine learning',\n","    'data science',\n","    'python',\n","    'word',\n","    'excel',\n","    'English',\n","    'Microsoft Azure',\n","    'SQL',\n","    'Power BI',\n","    'big data',\n","    'Client Server Technologies', \n","    'Stored Procedures', \n","    'Power BI', \n","    'Web Job', \n","    'Web App', \n","    'Power BI', \n","    'Microsoft', \n","    'Rewards Live', \n","    'Microsoft', \n","    'Microsoft Edge', \n","    'Excel', \n","    'Power BI', \n","    'Microsoft', \n","    'Rewards Data', \n","    'Microsoft', \n","    'Microsoft Edge', \n","    'Power BI', \n","    'Power BI', \n","    'Tool', \n","    'Azure Document', \n","    'Azure', \n","    'Web APP', \n","    'Angular JS', \n","    'Power BI', \n","    'Biztrack', \n","    'Angular JS', \n","    'User', \n","    'Skills Excellent', \n","    'Quick'\n","\n","]\n","\n","\n","def extract_text_from_docx(docx_path):\n","    txt = docx2txt.process(docx_path)\n","    if txt:\n","        return txt.replace('\\t', ' ')\n","    return None\n","\n","def skill_exists(skill):\n","    url = f'skill search api url'\n","    response = requests.request('GET', url, headers=headers)\n","    result = response.json()\n","\n","    if response.status_code == 200:\n","        return len(result) > 0 and result[0].lower() == skill.lower()\n","    raise Exception(result.get('message'))\n","\n","def extract_skills(input_text):\n","    stop_words = set(nltk.corpus.stopwords.words('english'))\n","    word_tokens = nltk.tokenize.word_tokenize(input_text)\n","\n","    # remove the stop words\n","    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n","\n","    # remove the punctuation\n","    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n","\n","    # generate bigrams and trigrams (such as artificial intelligence)\n","    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n","\n","    # we create a set to keep the results in.\n","    found_skills = set()\n","\n","    # for token in filtered_tokens:\n","    #     if skill_exists(token.lower()):\n","    #         found_skills.add(token)\n","\n","    # we search for each token in our skills database\n","    for token in filtered_tokens:\n","        if token.lower() in SKILLS_DB:\n","            found_skills.add(token)\n","\n","    # we search for each bigram and trigram in our skills database\n","    for ngram in bigrams_trigrams:\n","        if ngram.lower() in SKILLS_DB:\n","            found_skills.add(ngram)\n","\n","    return found_skills\n","\n","\n","# if __name__ == '__main__':\n","#     text = extract_text_from_pdf('Alice Clark CV.pdf')\n","#     skills = extract_skills(text)\n","\n","#     print(skills)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"EzGpi9CoHgn8","executionInfo":{"status":"error","timestamp":1640243273872,"user_tz":-330,"elapsed":423,"user":{"displayName":"Srikanth Vemula","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12636352860741150355"}},"outputId":"4e4357e4-35ff-47a4-f826-45ac92cbcc75"},"execution_count":4,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-844819f76cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdocx2txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'docx2txt'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["import docx2txt\n","import nltk\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","\n","\n","RESERVED_WORDS = [\n","    'school',\n","    'college',\n","    'univers',\n","    'academy',\n","    'faculty',\n","    'institute',\n","    'faculdades',\n","    'Schola',\n","    'schule',\n","    'lise',\n","    'lyceum',\n","    'lycee',\n","    'polytechnic',\n","    'kolej',\n","    'ünivers',\n","    'okul',\n","]\n","\n","\n","def extract_text_from_docx(docx_path):\n","    txt = docx2txt.process(docx_path)\n","    if txt:\n","        return txt.replace('\\t', ' ')\n","    return None\n","\n","\n","def extract_education(input_text):\n","    organizations = []\n","\n","    # first get all the organization names using nltk\n","    for sent in nltk.sent_tokenize(input_text):\n","        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n","            if hasattr(chunk, 'label') and chunk.label() == 'ORGANIZATION':\n","                organizations.append(' '.join(c[0] for c in chunk.leaves()))\n","\n","    # we search for each bigram and trigram for reserved words\n","    # (college, university etc...)\n","    education = set()\n","    for org in organizations:\n","        for word in RESERVED_WORDS:\n","            if org.lower().find(word) >= 0:\n","                education.add(org)\n","\n","    return education\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"dLXttK_QHhxb","executionInfo":{"status":"error","timestamp":1640243284043,"user_tz":-330,"elapsed":354,"user":{"displayName":"Srikanth Vemula","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12636352860741150355"}},"outputId":"5bfa1b18-e999-420e-c7f3-83306e9207ea"},"execution_count":5,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-4011848b9799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdocx2txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'docx2txt'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    # text = extract_text_from_pdf('Smith Resume.pdf')\n","    text = extract_text_from_docx('Smith Resume.docx')\n","    candidate_name = extract_names(text)\n","    candidate_mobile = extract_phone_number(text)\n","    candidate_email = extract_emails(text)\n","    candidate_skills = extract_skills(text)\n","    education_information = extract_education(text)\n","\n","print(candidate_name)\n","print(\"-------------\")\n","print(candidate_mobile)\n","print(\"-------------\")\n","print(candidate_email)\n","print(\"-------------\")\n","print(candidate_skills)\n","print(\"-------------\")\n","print(education_information)\n","print(\"-------------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"au9rk9wRHkIi","executionInfo":{"status":"error","timestamp":1640243289760,"user_tz":-330,"elapsed":331,"user":{"displayName":"Srikanth Vemula","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12636352860741150355"}},"outputId":"abe47093-27ca-4f7c-934d-9acce5633197"},"execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-774ec72ad3cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# text = extract_text_from_pdf('Smith Resume.pdf')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_docx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Smith Resume.docx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcandidate_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcandidate_mobile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_phone_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'extract_text_from_docx' is not defined"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"Nx-Vh3CJHlnA"},"execution_count":null,"outputs":[]}]}